{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c686eef7",
   "metadata": {},
   "source": [
    "# Workshop 9\n",
    "\n",
    "This workshop includes three exercises\n",
    "- a visualization of the negative log likelihood estimation\n",
    "- an introduction to the profiled log likelihood ratio\n",
    "- an exercise with data sample to be used for the final project\n",
    "\n",
    "The first and second exercises will be helpful for your homework 4. The last one will be useful for your final project.\n",
    "\n",
    "**Submit your completed notebook and the pdf version of it to the bcourse to receive credit. Please rename your files so that they start with your SID.**\n",
    "\n",
    "## Submission Deadline: 13:59 pm November 4, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0e0dd",
   "metadata": {},
   "source": [
    "# 1. Visualization of the negative log likelihood estimation\n",
    "\n",
    "This exercise consists of the following components:\n",
    "- data sample:\n",
    "    - the data sample is generated from a Gaussian PDF with a mean of 125 and a standard deviation of 2\n",
    "    - the entries of this sample are binned in the range of (100,160) with 60 bins and shown in a histogram; in other words, the sample include 60 independent measurements\n",
    "- construct the binned negative log likelihood function\n",
    "    - Histogram the data sample to create binned observed data\n",
    "    - Expectation: calculated from the normal distribution with a mean of 125 and a standard deviation of 2 at the bin centers of the histogram\n",
    "        - recall `PDF(x)dx` gives the probability of observing the outcome in the interval of $dx$\n",
    "        - so at a given point of $x$, the expectation is $x\\cdot dx$, where $dx$ is taken to be the bin width\n",
    "    - Calculate the negative log Poisson terms of the 60 independent measurements and sum them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook inline\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from matplotlib import animation, rc\n",
    "#sns.set_context('poster')\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaafddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code to generate 50 random numbers\n",
    "# from a normal distribution with a mean of 125\n",
    "# and a standard deviation of 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram the sample\n",
    "# Use 30 bins and a range of (110,140)\n",
    "# Get the bin centers as a numpy array\n",
    "# Get the bin counts (the number of entries in each bin) as a numpy array\n",
    "datacount, binedges = np.histogram(data,bins=30,range=(110,140))\n",
    "bincenters = 0.5*(binedges[:-1]+binedges[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf5e33",
   "metadata": {},
   "source": [
    "- Develop the negative log likelihood function here\n",
    "- **Read the comments very carefully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dde41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL(x,datacount, bincenters):\n",
    "    # the function has four input arguments\n",
    "    # x is a list, and its elements are [mean, sigma] of the normal distribution\n",
    "    # datacount is the bin count numpy array\n",
    "    # bincenters is the np array of bincenters\n",
    "    # binwidth is a scalar, given by (max-min)/nbins\n",
    "    \n",
    "\n",
    "    # norm.pdf(bincenters,x[0],x[1]) gives the PDF values at a series of points\n",
    "    # binwidth is the interval (\"dx\")\n",
    "    binwidth = bincenters[1]-bincenters[0]\n",
    "    expectation_without_normalization = norm.pdf(bincenters,x[0],x[1])*binwidth\n",
    "\n",
    "    # the sum of expectation_without_normalization should be 1 \n",
    "    # because the total probability is 1\n",
    "    # the line below gives the expectation normalized to number of entries in the sample\n",
    "    expectation = expectation_without_normalization*datacount.sum()\n",
    "\n",
    "    # three important elements below\n",
    "    # negative => -1*\n",
    "    # log likelihood => log.pmf\n",
    "    # sum. you should sum up all the individual measurement terms ==> .sum()\n",
    "    return -1*poisson.logpmf(datacount,expectation).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3f8d3",
   "metadata": {},
   "source": [
    "Minimize the negative log likelihood value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23038be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(NLL, # objective function\n",
    "                  [126,1], # initial values for the free parameters \n",
    "                  args=(datacount, bincenters), # other input arguments to the minimization\n",
    "                  method='Nelder-Mead' # minimization method\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the fit result\n",
    "print(result) \n",
    "\n",
    "#Retrive information from the fit results\n",
    "mean,std = result.x\n",
    "NLLvalue = result.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93ead9",
   "metadata": {},
   "source": [
    "## Visualization \n",
    "\n",
    "Complete the code cell below\n",
    "**example output plot**\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig1.png\" width='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data,bins=30,range=(110,140), label='Generated random data')\n",
    "\n",
    "# Recycle the code used earlier to get the \n",
    "# expectation \n",
    "# Note that the mean and std parameters of the normal\n",
    "# function are now from the fit result\n",
    "\n",
    "# Add the missing line back\n",
    "\n",
    "expectation_without_normalization = norm.pdf(bincenters,result.x[0],result.x[1])\n",
    "\n",
    "\n",
    "plt.plot(bincenters,expectation,'r--',label='Fitted Normal distribution')\n",
    "plt.xlim(120,130)\n",
    "plt.ylim(0, np.max(datacount)*1.5)\n",
    "plt.legend(loc='upper right', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c956a1d0",
   "metadata": {},
   "source": [
    "- when we define the NLL function, we need to calculate the expectation from the PDF, and we need to normalize the expectation to that of the observation. This was done by the line `expectation = expectation_without_normalization*datacount.sum()`\n",
    "- we will define a new NLL function, named as `NLL_v2`, where we leave the normalization of the expectation to be a free parameter, and we let the minimization (fit) decide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f940841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how this cell differs from the cell where NLL was defined\n",
    "def NLL_v2(x,datacount, bincenters):\n",
    "    # the function has four input arguments\n",
    "    # x is a list, and its elements are [mean, sigma] of the normal distribution\n",
    "    # datacount is the bin count numpy array\n",
    "    # bincenters is the np array of bincenters\n",
    "    # binwidth is a scalar, given by (max-min)/nbins\n",
    "    \n",
    "\n",
    "    # norm.pdf(bincenters,x[0],x[1]) gives the PDF values at a series of points\n",
    "    # binwidth is the interval (\"dx\")\n",
    "    binwidth = bincenters[1]-bincenters[0]\n",
    "    expectation_without_normalization = norm.pdf(bincenters,x[0],x[1])*binwidth\n",
    "\n",
    "    # the sum of expectation_without_normalization should be 1 \n",
    "    # because the total probability is 1\n",
    "    # the line below gives the expectation normalized to number of entries in the sample\n",
    "    expectation = expectation_without_normalization*x[2]\n",
    "\n",
    "    # three important elements below\n",
    "    # negative => -1*\n",
    "    # log likelihood => log.pmf\n",
    "    # sum. you should sum up all the individual measurement terms ==> .sum()\n",
    "    return -1*poisson.logpmf(datacount,expectation).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_v2 = minimize(NLL_v2, # objective function\n",
    "                  [126,1,10], # initial values for the free parameters \n",
    "                  args=(datacount, bincenters), # other input arguments to the minimization\n",
    "                  method='Nelder-Mead' # minimization method\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03743462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the fit result\n",
    "print(result_v2) \n",
    "\n",
    "#Retrive information from the fit results\n",
    "mean,std, normalizationfactor = result_v2.x\n",
    "NLLvalue = result_v2.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa4fea",
   "metadata": {},
   "source": [
    "What is the value of x[2] here? What value should it be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd379d",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "- in the cell blow, we use ipywidgets package to create a control that allows you to tune the mean value and the standard deviation value (std) of the Normal distribution \"by hand\". \n",
    "- the initial values of these parameters are taken from the minimization (fit) results \n",
    "- vary the value of mean, and see\n",
    "    - on the top panel, how the expected normal distribution shifts\n",
    "    - on the bottom panel, how the negative log likelihood value varies\n",
    "- **in the markdown cell below, type the measured central value as well as it uncertainties**. You can tell these by varying the mean value and see how the NLL changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(mean=widgets.FloatSlider(min=124.0, max=125.0, step=0.001, value=result.x[0],layout=widgets.Layout(width='40%') , readout_format='.3f'), std=widgets.FloatSlider(min=0.1, max=3.141, step=0.1, value=result.x[1]), continuous_update=True)\n",
    "def draw_plt(mean, std):\n",
    "    fig, axs = plt.subplots(3,1,figsize=(16,9), gridspec_kw={'height_ratios': [3, 1, 2]})\n",
    "    plt.subplot(311)\n",
    "    plt.hist(data,bins=30,range=(110,140))\n",
    "\n",
    "\n",
    "\n",
    "    reference = norm.pdf(bincenters,125,2)*binwidth*datacount.sum()\n",
    "    expectation = norm.pdf(bincenters,mean,std)*binwidth*datacount.sum()\n",
    "    plt.plot(bincenters,expectation,'r--',label=\"Expectation\")\n",
    "    plt.plot(bincenters,reference,'g--',label=\"Reference\")\n",
    "    plt.xlim(120,130)\n",
    "    plt.ylim(0,1.2*datacount.max())\n",
    "    plt.legend()\n",
    "    plt.ylabel('Number of entries',fontsize=14)\n",
    "    \n",
    "    # Plot the residual\n",
    "    plt.subplot(312)\n",
    "    residual = datacount - expectation \n",
    "    plt.errorbar(bincenters, residual, yerr=np.sqrt(datacount), fmt='o',color='black')\n",
    "    plt.xlim(120,130)\n",
    "    plt.ylabel('Residual: data - fit',fontsize=14)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.subplot(313)\n",
    "\n",
    "    mass = np.linspace(110,140,3001)\n",
    "    NLLval=np.ones(0)\n",
    "    for m in mass:\n",
    "        NLLval = np.hstack( (NLLval,  NLL_v2([m,std,50], datacount,bincenters)))\n",
    "\n",
    "    NLLmin = NLLval.min()    \n",
    "    NLLval = NLLval - NLLmin\n",
    "    \n",
    "    NLL_parameters = NLL_v2([mean,std, 50], datacount,bincenters ) - NLLmin\n",
    "    \n",
    "    plt.plot(mass,NLLval)\n",
    "    plt.scatter(mean, NLL_parameters, color=\"red\",label='Current NLL value')\n",
    "    # print(mean, NLL_parameters)\n",
    "    plt.ylim(0,4)\n",
    "    plt.ylabel('NLL',fontsize=14)\n",
    "    plt.xlim(result.x[0]-0.5,result.x[0]+0.5)\n",
    "    plt.plot([123.,126.5],[0.5,0.5],'r--')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4c3e0",
   "metadata": {},
   "source": [
    "# Type down the $\\pm 1 \\sigma$ uncertainty in this cell \n",
    "\n",
    "\n",
    "# Mean = 1xx.xx $^{+ yy}_{-zz}$\n",
    "\n",
    "for example, 127.32$^{+0.91}_{-0.32}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9465ec4",
   "metadata": {},
   "source": [
    "# 2. Hypothesis testing and profile likelihood ratio\n",
    "\n",
    "- in this exercise, we define two different hypotheses, namely, the b-only hypothesis and the signal-plus-background hypothesis\n",
    "- then, we generate one data set, which is considered as the observed data\n",
    "- we will test this observed data set against the B-only hypothesis and determine the p-value of the observed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this experiment, there are 50 independent observations\n",
    "# the b-only expectation is given by the line below\n",
    "B = np.arange(50,100)\n",
    "\n",
    "# the signal expectation is give by \n",
    "S = norm.pdf(np.linspace(50,100,50),75,2)*50\n",
    "\n",
    "\n",
    "# The signal-plus-background expectation is given by\n",
    "SB = B + S\n",
    "\n",
    "# Observed data is given by\n",
    "obs = np.array([51,49,44,58,48,68,62,49,61,61,83,52,64,82,66,78,70,67,60,78,74,72,69,77,81,92,85,84,66,77,75,81,81,96,89,85,72,77,76,106,95,104,110,99,113,91,93,77,100,79])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae388ddc",
   "metadata": {},
   "source": [
    "**Complete the code cell below to visualize the data and hypotheses**\n",
    "\n",
    "**Example output**\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig2.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the hypotheses and the observed data \n",
    "\n",
    "plt.subplots(figsize=(8,6))\n",
    "bincount, binedges, others=plt.hist(obs[0],bins=50,range=(50,100))\n",
    "bincenters = (binedges[1:]+binedges[0:-1])*0.5\n",
    "plt.hist(bincenters, bins=50, range=(50,100),weights=S+B,histtype=\"step\",ls='dashed',color='red',label=\"Expected signal\")\n",
    "plt.hist(bincenters, bins=50, range=(50,100),weights=B,color='green',label=\"Background\")\n",
    "plt.errorbar(bincenters, obs, yerr=np.sqrt(obs), fmt='o',color='black')\n",
    "\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.xlim(50,100)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55083bc5",
   "metadata": {},
   "source": [
    "## Define the negative log likelihood function \n",
    "\n",
    "## $$\n",
    "  NLL(\\mu) = \\sum_i{ -\\log{Pois}(d_i| \\mu s_i + b_i)}\n",
    "$$\n",
    "\n",
    "where $i$ is the index of the bin. {$s_i$} and {$b_i$} are given by the numpy arrays S and B, respectively, $\\mu$ is the signal strength parameter that scales up and down the signal expectation, and {$d_i$} is the experimental outcome from either real data or pseudo experiments. When $\\mu$ = 0, this expression becomes the negative log likelihood for the b-only hypothesis. When $\\mu$ = 1, this expression gives the negative log likelihood for the signal-plus-background hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc305e5",
   "metadata": {},
   "source": [
    "**Reshape arrays to have 2 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61853276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These arrays will now have 2 dimensions\n",
    "# the values are on the axis 1\n",
    "# there is one entry on axis 0\n",
    "# This will make it easier for caluclations that involve pseudo experiments\n",
    "# for which PE data are saved as arrays of shape (N,50)\n",
    "# where N is the number of pseudo experiments\n",
    "S=S.reshape(1,50)\n",
    "B=B.reshape(1,50)\n",
    "obs=obs.reshape(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbccec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define this function for scipy.optimize.minimize\n",
    "# the first argument must be the free parameter\n",
    "# that's determined by the minimization\n",
    "# the next three are the S, B, and observed data\n",
    "def NLLfunc(x,S,B,obs):\n",
    "    exp = x[0]*S+B\n",
    "    # the second argument, axis = 1, implies that\n",
    "    # these arrays (obs, exp) have more than one axes\n",
    "    return np.sum(-poisson.logpmf(obs,exp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10,000 Pseudo experiments from b-only hypothesis\n",
    "BPE = rng.poisson(B,size=(10000,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e683c0",
   "metadata": {},
   "source": [
    "## Test statistic 1: Negative Log Likelihood Ratio\n",
    "\n",
    "## $$NLLR = -2\\log\\frac{L(data|s+b)}{L(data|b-only)}\n",
    "$$\n",
    "\n",
    "- calculate the NLLR for each PE\n",
    "- calculate the observed NLLR (i.e., the NLLR value for the observed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLLR values for the PEs\n",
    "# These can be done with three simple lines \n",
    "NLLSB = NLLfunc([1], S, B, BPE)\n",
    "NLLB = NLLfunc([0], S, B, BPE)\n",
    "NLLR = 2*(NLLSB - NLLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97024b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NLLR value for the observed data\n",
    "NLLSB_obs = NLLfunc([1], S, B, obs)\n",
    "NLLB_obs = NLLfunc([0], S, B, obs)\n",
    "NLLR_obs = 2*(NLLSB_obs - NLLB_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35522d56",
   "metadata": {},
   "source": [
    "**Complete the cell below to visualize the hypothesis testing with P.E.s**\n",
    "\n",
    "**Example output**\n",
    "\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig3.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the PE based hypothesis testing\n",
    "\n",
    "# fix the lines below\n",
    "plt.hist(,bins=50,range=(-20,20),label='B-only P.E.s')\n",
    "plt.hist(,bins=50,range=(-20,20),color='magenta',label='Tail NLLR < NLLR$_{obs}$')\n",
    "plt.plot([],[0, 300],label='Observed LLR')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.xlabel('Negative Log Likelihood Ratio (NLLR)')\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a439c1",
   "metadata": {},
   "source": [
    "- The magneta area gives the fraction of PE outcomes that are more extreme than the observed data outcome\n",
    "- the p-value is the fraction of outcomes corresponding to the magenta area\n",
    "- the significance can be converted from the p-value using Z = norm.ppf(1-pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code to tell us the p-value and the significance of rejecting the background only hypothesis\n",
    "\n",
    "pvalue=\n",
    "Z = \n",
    "print('p-value of the background-only hypothesis is {:1.4f}'.format(pvalue))\n",
    "print('the Statistical significance of rejecting the background only hypothesis is {:1.2f}'.format(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d678e",
   "metadata": {},
   "source": [
    "## Test statistic 2: Profile Likelihood Ratio\n",
    "\n",
    "## $$PLR = -2\\log\\frac{L(data|b-only)}{L(data|\\hat{\\mu}S+B)}\n",
    "$$\n",
    "The numerator is the likelihood constructed from data and the background only hypothesis, and the denominator is the likelihood constructed from data and the $\\mu$ times Signal-plus-background hypothesis, where the signal strength parameter is determined by minimizing the negative log likelihood hood.\n",
    "\n",
    "- unlike the first test statistic, the denominator of the PLR requires a minimization of the negative log likelihood\n",
    "- the only free parameter in this example is $\\mu$; varying the $\\mu$ value will lead to a minimized negative log likelihood function\n",
    "- **The hypothesis that appears at the numerator is the one that we test**\n",
    "- **The free parameter that appears at the denominator is the parameter of interest**, which defines the hypothesis.\n",
    "- **The PoI in the numerator is fixed to the value of the hypothesis.** In this case, b-only hypothesis requries $\\mu$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56318890",
   "metadata": {},
   "source": [
    "**First, as an exercise, let's develop the code to calculate the PLR value for the observed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the PLR for the observed data\n",
    "\n",
    "# Minimize the negative log likelihood function created earlier\n",
    "# only one free parameter \n",
    "result_obs = minimize(NLLfunc,[1], bounds=[(0,10)],args=(S,B,obs))\n",
    "\n",
    "# the minimization result would return the minimized objective function\n",
    "NLLmufree_obs = result_obs.fun\n",
    "\n",
    "# NLLfunc([0], S, B, obs) gives the numerator of the PLR\n",
    "PLR_obs = 2*(NLLfunc([0], S, B, obs) -  NLLmufree_obs)\n",
    "\n",
    "print(PLR_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb08bb",
   "metadata": {},
   "source": [
    "**Now, let's calculate the PLR values for the b-only pseudo experiments that we generated earlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdedd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will have to do a for-loop here\n",
    "\n",
    "# all the PLR values from the P.E.s will be stored in the numpy array PLR\n",
    "PLR = np.ones(0)\n",
    "\n",
    "# all the fitted mu values from the P.E.s will be stored in the numpy array Fitted_mu \n",
    "Fitted_mu = np.ones(0)\n",
    "\n",
    "for PE in BPE:\n",
    "    # if you are not familiar with this \n",
    "    # check out the shape of PE and BPE here\n",
    "    \n",
    "    # Write your code to calculate the PLR for this current PE\n",
    "    # Just follow the example given to you in the previous cell\n",
    "    result = minimize(     args=(S,B,PE))\n",
    "    NLLmufree = \n",
    "    NLLB = \n",
    "    PLR_PE = \n",
    "\n",
    "    \n",
    "    PLR = np.hstack( (PLR, PLR_PE))\n",
    "    Fitted_mu = np.hstack( (Fitted_mu, result.x[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4d2ce",
   "metadata": {},
   "source": [
    "**Complete the cell below to visualize the hypothesis testing with P.E.s**\n",
    "\n",
    "**Example output**\n",
    "\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig4.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d649a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fix this cell\n",
    "\n",
    "plt.hist(,bins=25,range=(0,25),label='B-only P.E.s')\n",
    "\n",
    "plt.hist(,bins=25,range=(0,25),color='magenta',label='tail (PLR > PLR$_obs$)')\n",
    "# Note that the magenta entry on the left of the vertical line is a binning effect\n",
    "# The bin edges and the observed PLR value are not perfectly aligned\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.plot([,[0,1000], label='Observed PLR')\n",
    "\n",
    "# Generating a chi-2 distribution as a reference\n",
    "chi2_curve = chi2.pdf(np.linspace(0.5,24.5,25),1)*0.5*PLR.size\n",
    "plt.plot(np.linspace(0.5,24.5,25), chi2_curve,label='chi-2 distribution')\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b01169",
   "metadata": {},
   "source": [
    "### Now, use the profile likelihood ratio based test statistic to calculate the p-value significance\n",
    "#### from pseudo experiments\n",
    "- the p-value is the fraction of outcomes corresponding to the magenta area\n",
    "- the significance can be converted from the p-value using Z = norm.ppf(1-pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = \n",
    "Z = \n",
    "print('p-value of the background-only hypothesis is {:1.4f}'.format(pvalue))\n",
    "print('the Statistical significance of rejecting the background only hypothesis is {:1.2f}'.format(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff64b19",
   "metadata": {},
   "source": [
    "### analytically\n",
    "We introduced the PLR because its distribution is known. If the hypothesis to test (the one that appears at the numerator of the PLR) and the hypothesis used to generate the pseudo experiments are the same, then the PLR distribtuion of the P.E.s is a chi-squared distribution, which is illustrated in the figure above.\n",
    "\n",
    "-**We also know that the observed significance is given by** \n",
    "## $$Z = \\sqrt{PLR_{obs}}$$\n",
    "\n",
    "- now use this relation to calculate the significance, and then convert the significance to the p-value. Do they agree with your earlier calculation using the NLLR?\n",
    "- The advantage of using the PLR is that we do not have to generate a large number of P.E.s when the observed significance is large. We only need to calculate the PLR$_obs$, and its square-root gives the observed signfiicance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cf19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = \n",
    "# This is how you get pvalue, knowing Z\n",
    "pvalue = 1-norm.cdf(Z)\n",
    "print('p-value of the background-only hypothesis is {:1.4f}'.format(pvalue[0]))\n",
    "print('the Statistical significance of rejecting the background only hypothesis is {:1.2f}'.format(Z[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f9eea",
   "metadata": {},
   "source": [
    "# 3. Final Project Data\n",
    "\n",
    "- Data for the final project are saved in a h5 file. We will show you how to get this h5 file and how to retrieve the data numpy array\n",
    "- We will also use this data set to do some binned maximum log likelihood fit exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading this h5 file from the web\n",
    "import os\n",
    "os.system(\"wget https://portal.nersc.gov/project/m3438/physics77/data/datalhc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fed688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open h5 file\n",
    "h = h5py.File(\"datalhc.h5\",'r')\n",
    "\n",
    "# Retrieve the data array \n",
    "data = h[\"dataset\"][:]\n",
    "\n",
    "# Check its shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c67f33",
   "metadata": {},
   "source": [
    "The shape of data array is (1178902, 10), indicating that there are 1,178,902 collision events that contain two photons. The axis 1 has 10 entries. They are\n",
    "\n",
    "- transverse momentum of photon 1\n",
    "- pseudo rapidity of photon 1\n",
    "- azimuthal angle of photon 1\n",
    "- energy of photon 1\n",
    "- transverse momentum of photon 2\n",
    "- pseudo rapidity of photon 2\n",
    "- azimuthal angle of photon 2\n",
    "- energy of photon 2\n",
    "- Event Number, which is an index of the collision event\n",
    "- Run Number, which is an index of a `run`. At LHC, the detector is often run for an extended period of time, raning from a few minuts to a few hours. Data events collected in the same data taking period are said to be in the same `run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here a few functions are defined to get the px, py, pz components of the momentum\n",
    "\n",
    "def px(pt, phi):\n",
    "    return pt*np.cos(phi)\n",
    "\n",
    "def py(pt,phi):\n",
    "    return pt*np.sin(phi)\n",
    "\n",
    "def pz(pt, eta):\n",
    "    return pt*np.sinh(eta)\n",
    "\n",
    "\n",
    "# Using energy and momentum we can calculate the mass of a particle or a multi-particle system\n",
    "def mass(E,px,py,pz):\n",
    "    return np.sqrt(E**2 - (px**2+py**2+pz**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the functions defined above to calculate \n",
    "# the px, py, pz components of the diphoton momentum\n",
    "px_yy = \n",
    "py_yy =\n",
    "pz_yy = \n",
    "\n",
    "# We will also calculate the energy of the diphoton system\n",
    "# which is the sum of individual photons\n",
    "E_yy = \n",
    "\n",
    "# Finally, we can calculate the diphoton mass\n",
    "m_yy = mass(E_yy, px_yy,py_yy,pz_yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e805dd",
   "metadata": {},
   "source": [
    "## Plot the $m_{\\gamma\\gamma}$ distribution\n",
    "- a tiny bump around 125 GeV is already discernible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca46947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the diphoton mass distribution look like?\n",
    "\n",
    "obs, binedges,others =plt.hist(m_yy,bins=55,range=(105,160),label='Data 2015-2018')\n",
    "plt.xlabel('$m_{\\gamma\\gamma}$ [GeV]')\n",
    "plt.ylabel('Number of entries')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0f3bc",
   "metadata": {},
   "source": [
    "## Use the maximum log likelihood method to fit a 4th order polynomial to data\n",
    "- define a 4th order polynomial function, `poly4`\n",
    "- define the NLL for this `poly4`. \n",
    "    - For the sake of simplicity, we calculate the value of the polyminomial at np.linspace(105.5,159.5,55), i.e., the bin centers of the above histogram. The binwidth is 1\n",
    "- Use scipy.optimize.minimize to perform the fit, in which the coefficients of the terms are determined\n",
    "- Visualize the fitted Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe163d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a fourth-order polynomial\n",
    "def poly4(myy,c):\n",
    "    return 1 + c[0]*myy + c[1]*myy**2 + c[2]*myy**3 + c[3]*myy**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLLpoly(c, obs):\n",
    "    # Create a sequence of values at which the expectation will be evaluated\n",
    "    myy = np.linspace(105.5,159.5,55)\n",
    "    # The expectaiton. Note that the c[4] factor will take care of the normalization of the polynomial PDF\n",
    "    exp = poly4(myy, [c[0],c[1],c[2],c[3]])*c[4]\n",
    "    # return a negative log likelihood\n",
    "    # again, needs to sum over all 55 bins\n",
    "    NLLvalue = -1*poisson.logpmf(obs,exp).sum()\n",
    "    return NLLvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98db01a",
   "metadata": {},
   "source": [
    "### Fit the 4th order polynomial to data\n",
    "- print out the fit result\n",
    "- visualize the fitted function and data distribution\n",
    "**Does the fit make sense?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35957fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(NLLpoly,x0=[-10,100,1,1,1],args=(obs),method='Nelder-Mead')\n",
    "print(result)\n",
    "\n",
    "# Pass the fitted values back to the list c\n",
    "c=result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a730eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted coefficients to create the expectation\n",
    "myy = np.linspace(105.5,159.5,55)\n",
    "fit = poly4(myy, [c[0],c[1],c[2],c[3]])*c[4]\n",
    "\n",
    "# Data\n",
    "obs, binedges,others =plt.hist(m_yy,bins=55,range=(105,160), label='data')\n",
    "plt.plot(myy,fit,'r--', label='Fitted Polynomial')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel('$m_{\\gamma\\gamma}$ [GeV]')\n",
    "plt.ylabel('Number of entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501318a",
   "metadata": {},
   "source": [
    "## Execute the next cell repeatedly\n",
    "- the minimization algorithm is pretty rudimentary. It doesn't perform well. \n",
    "- the first fit is unlikely to be a good one\n",
    "- in the next cell, we pass the fit result to c, and use them as the initial value in a new iteration of minimization\n",
    "- repeatedly execute the next cell and see if the NLL decreases and if the fit continues to improve\n",
    "\n",
    "**Your final fit plot should look like **\n",
    "\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig6.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(NLLpoly,x0=c,args=(obs),method='Nelder-Mead')\n",
    "print('Pay attention to the NLL value {:6.3f}'.format(result.fun))\n",
    "c=result.x\n",
    "fit = poly4(myy, [c[0],c[1],c[2],c[3]])*c[4] \n",
    "obs, binedges,others =plt.hist(m_yy,bins=55,range=(105,160), label='data')\n",
    "plt.plot(myy,fit,'r--', label='Fitted Polynomial')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel('$m_{\\gamma\\gamma}$ [GeV]')\n",
    "plt.ylabel('Number of entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The minimized NLL value with bkg-only PDF is {:5.2f}\".format(   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6100cd",
   "metadata": {},
   "source": [
    "## Fit data with a signal plus background PDF\n",
    "- In this exercise, we will create a different function\n",
    "$$\n",
    "f(x=m_{\\gamma\\gamma}) = n_b \\sum_i c_i x^i + n_s \\mathrm{Normal}(x,125,1.6)\n",
    "$$\n",
    "    - in this setup, the first term is a fourth order polynomial, and its normalized to $n_b$ which is the number of background events. The second term is a normal distribution with a mean of 125 and a standard deviation of 1.6, and its normalization $n_s$ represents the number of signal events. \n",
    "    - the shape (mean and std. dev.) of the Gaussian distribution is fixed \n",
    "    - the free parameters in the fit include\n",
    "        - the coefficients of the polynomial\n",
    "        - the normalizations of the signal and background PDFs ($n_s$ and $n_b$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eef9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the signal pdf\n",
    "\n",
    "def sigpdf(myy,mean,std):\n",
    "    return norm.pdf(myy,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e43b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define negative log likelihood value with the observed data and the signal plus background PDF\n",
    "def NLLSpluspoly(c, obs):\n",
    "    myy = np.linspace(105.5,159.5,55)\n",
    "    exp = poly4(myy, [c[0],c[1],c[2],c[3]])*c[4] + sigpdf(myy,125,1.6)*c[5]\n",
    "    NLLvalue = -1*poisson.logpmf(obs,exp).sum()\n",
    "    return NLLvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37543db0",
   "metadata": {},
   "source": [
    "Now we perform an initial fit to the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cce13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that I am using the coefficients determined from the previous fits as the\n",
    "# initial values here\n",
    "result = minimize(NLLSpluspoly,x0=np.hstack((c,1000)),args=(obs),method='Nelder-Mead')\n",
    "c1=result.x\n",
    "print('Pay attention to the NLL value {:6.3f}'.format(result.fun))\n",
    "myy = np.linspace(105.5,159.5,55)\n",
    "fit = poly4(myy, [c1[0],c1[1],c1[2],c1[3]])*c1[4] + sigpdf(myy,125,1.6)*c1[5]\n",
    "# Data\n",
    "obs, binedges,others =plt.hist(m_yy,bins=55,range=(105,160), label='data')\n",
    "plt.plot(myy,fit,'r--', label='Fitted Polynomial')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel('$m_{\\gamma\\gamma}$ [GeV]')\n",
    "plt.ylabel('Number of entries')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b602d",
   "metadata": {},
   "source": [
    "### Execute the cell below repeatedly to see if fit gets improved?\n",
    "\n",
    "**Final output**\n",
    "\n",
    "<img src=\"https://portal.nersc.gov/project/m3438/physics77/WS09/fig7.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d435e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = minimize(NLLSpluspoly,x0=c1,args=(obs),method='Nelder-Mead')\n",
    "c1=result.x\n",
    "print('Pay attention to the NLL value {:6.3f}'.format(result.fun))\n",
    "myy = np.linspace(105.5,159.5,55)\n",
    "fit = poly4(myy, [c1[0],c1[1],c1[2],c1[3]])*c1[4] + sigpdf(myy,125,1.6)*c1[5]\n",
    "# Data\n",
    "obs, binedges,others =plt.hist(m_yy,bins=55,range=(105,160), label='data')\n",
    "plt.plot(myy,fit,'r--', label='Fitted Polynomial')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel('$m_{\\gamma\\gamma}$ [GeV]')\n",
    "plt.ylabel('Number of entries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The fitted number of signal events is {:4.2f} '.format(   ))\n",
    "\n",
    "print(\"The minimized NLL value with signal-plus-bkg PDF is {:5.2f}\".format(   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236f615",
   "metadata": {},
   "source": [
    "## Can you develop the code to fit the data with a signal plus background pdf where the mean and sigma of the signal pdf are also free?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLLSpluspolyfree(c, obs):\n",
    "\n",
    "    # complete the cell here\n",
    "    \n",
    "    return NLLvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d710b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd683214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The fitted mean value of the signal is {:4.2f} GeV'.format(  ))\n",
    "print('The fitted sigma value of the signal is {:4.2f} GeV'.format( ))\n",
    "print('The fitted number of signal events is {:4.2f} '.format(  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7392efd",
   "metadata": {},
   "source": [
    "Congratulations for completing this workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85f5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
